bb$over_bb_dn <- 0
View(bb)
for (i in 7:length(bb$positive_ratio)) {
if (bb$positive_ratio[[i]] > bb$up[[i]]) {
bb$over_bb_up[[i]] <- 1
} else if (bb$positive_ratio[[i]] < bb$dn[[i]]) {
bb$over_bb_dn[[i]] <- 1
}
}
addTA(c(bb$over_bb_up, bb$over_bb_dn), col = c("brown","orange" ), type = "h")
View(num_of_volume_df)
## negative
chartSeries(num_of_volume_df[, 6], theme = "white", name = "positive")
addBBands(n = 7, sd = 2)
addSMA(n = 7, col = "blue")
# BBands's up and down
bb <- BBands(num_of_volume_df[, 6], sd = 2, n = 7)
bb$negative_ratio <- num_of_volume_df$negative_ratio
bb$over_bb_up <- 0
bb$over_bb_dn <- 0
View(bb)
for (i in 7:length(bb$negative_ratio)) {
if (bb$negative_ratio[[i]] > bb$up[[i]]) {
bb$over_bb_up[[i]] <- 1
} else if (bb$negative_ratio[[i]] < bb$dn[[i]]) {
bb$over_bb_dn[[i]] <- 1
}
}
addTA(c(bb$over_bb_up, bb$over_bb_dn), col = c("brown","orange" ), type = "h")
## negative
chartSeries(num_of_volume_df[, 6], theme = "white", name = "negative")
addBBands(n = 7, sd = 2)
addSMA(n = 7, col = "blue")
# BBands's up and down
bb <- BBands(num_of_volume_df[, 6], sd = 2, n = 7)
bb$negative_ratio <- num_of_volume_df$negative_ratio
bb$over_bb_up <- 0
bb$over_bb_dn <- 0
for (i in 7:length(bb$negative_ratio)) {
if (bb$negative_ratio[[i]] > bb$up[[i]]) {
bb$over_bb_up[[i]] <- 1
} else if (bb$negative_ratio[[i]] < bb$dn[[i]]) {
bb$over_bb_dn[[i]] <- 1
}
}
addTA(c(bb$over_bb_up, bb$over_bb_dn), col = c("brown","orange" ), type = "h")
## neutral
chartSeries(num_of_volume_df[, 7], theme = "white", name = "neutral")
addBBands(n = 7, sd = 2)
addSMA(n = 7, col = "blue")
# BBands's up and down
bb <- BBands(num_of_volume_df[, 7], sd = 2, n = 7)
bb$neutral_ratio <- num_of_volume_df$neutral_ratio
bb$over_bb_up <- 0
bb$over_bb_dn <- 0
View(bb)
for (i in 7:length(bb$neutral_ratio)) {
if (bb$neutral_ratio[[i]] > bb$up[[i]]) {
bb$over_bb_up[[i]] <- 1
} else if (bb$neutral_ratio[[i]] < bb$dn[[i]]) {
bb$over_bb_dn[[i]] <- 1
}
}
addTA(c(bb$over_bb_up, bb$over_bb_dn), col = c("brown","orange" ), type = "h")
set.seed(123)
reps <- 10000
par.est <- matrix(0, reps, 6)
View(par.est)
?matrix
# DGP 2
b0 <- 0.2
b1 <- 0.5
n <- 1000 # sample size
X <- runif(n, -1, 1)
gamma <- 1.5
for (i in 1:reps){
Y <- b0 + b1 * X + rnorm(n, 0, exp(X * gamma)) # the heteroskedastic
model <- lm(Y ~ X)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
par.est[i, 5] <- sqrt(diag(vcovHC(model, type = "HC0"))[1]) # HC SE
par.est[i, 6] <- sqrt(diag(vcovHC(model, type = "HC0"))[2]) # HC SE
}
library(sandwich)
library(sandwich)
set.seed(123)
reps <- 10000
par.est <- matrix(0, reps, 6)   # 10000 rows, 6 columns
# DGP 2
b0 <- 0.2
b1 <- 0.5
n <- 1000 # sample size
X <- runif(n, -1, 1)
gamma <- 1.5
for (i in 1:reps){
Y <- b0 + b1 * X + rnorm(n, 0, exp(X * gamma)) # the heteroskedastic
model <- lm(Y ~ X)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
par.est[i, 5] <- sqrt(diag(vcovHC(model, type = "HC0"))[1]) # HC SE
par.est[i, 6] <- sqrt(diag(vcovHC(model, type = "HC0"))[2]) # HC SE
}
View(par.est)
nrow(par.est)
reps
View(par.est)
par.est[1, 2]
# (a)
# Compute the coverage probability of the 95% CI for β1 using the OLS standard error.
cnt <- 0
for (i in 1:reps) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 4]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 4]
if (b1 <= ci_upper && b1 >= ci_lower) {
cnt <- cnt + 1
}
}
coverage_probability <- cnt / reps
## (b)
## Compute the coverage probability of the 95% CI for β1 using the HC standard error.
cnt <- 0
for (i in 1:reps) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 <= ci_upper && b1 >= ci_lower) {
cnt <- cnt + 1
}
}
# 0.8685
coverage_probability <- cnt / reps
## (c)
## Plot the first 200 CIs in (b) and identify the CIs in color red that don’t cover true β1.
ci_lower <- c()
ci_upper <- c()
for (i in 1:200) {
ci_lower <- c(ci_lower, par.est[i, 2] - 1.96 * par.est[i, 6])
ci_upper <- c(ci_upper, par.est[i, 2] + 1.96 * par.est[i, 6])
}
library(plotrix)
require(plotrix)
install.packages(plotrix)
install.packages("plotrix")
library(plotrix)
?plotCI
beta1_hat <- par.est[ ,2]
beta1_hat <- par.est[ ,2][1:200]
plotCI(beta1_hat, x, ui=ci_upper, li=ci_lower)
x <- 1:200
plotCI(beta1_hat, x, ui=ci_upper, li=ci_lower)
plotCI(x, beta1_hat, ui=ci_upper, li=ci_lower)
library(ggplot2)
data <- data.frame(x = x, y = beta1_hat, lower = ci_lower, upper = ci_upper)
View(data)
ggplot(data, aes(x, y)) +        # ggplot2 plot with confidence intervals
geom_point() +
geom_errorbar(aes(ymin = lower, ymax = upper))
data <- data.frame(n = x, beta1_hat = beta1_hat, lower = ci_lower, upper = ci_upper)
ggplot(data, aes(n, beta1_hat)) +        # ggplot2 plot with confidence intervals
geom_point() +
geom_errorbar(aes(ymin = lower, ymax = upper))
## (c)
## Plot the first 200 CIs in (b) and identify the CIs in color red that don’t cover true β1.
plot(x=c(0, 200), y=c(-0.2,1.2), type = "n")
## (c)
## Plot the first 200 CIs in (b) and identify the CIs in color red that don’t cover true β1.
plot(n = c(0, 200), Xbar = c(-0.2,1.2), type = "n")
plot(x = n, y = Xbar, type = "n")
Xbar <- c(-0.2,1.2)
plot(x = n, y = Xbar, type = "n")
## (c)
## Plot the first 200 CIs in (b) and identify the CIs in color red that don’t cover true β1.
n <- c(0, 200)
Xbar <- c(-0.2,1.2)
plot(x = n, y = Xbar, type = "n")
plot(x = Xbar, y = n, type = "n")
abline(v = 0.5, lty = 2, col = "red")
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && bi <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, color = "black")
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, color - "red")
}
}
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, color = "black")
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, color - "red")
}
}
?lines
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, type = "black")
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, type =  "red")
}
}
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1)
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1)
}
}
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 1)
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 2)
}
}
library(sandwich)
set.seed(123)
reps <- 10000
par.est <- matrix(0, reps, 6)   # 10000 rows, 6 columns
# DGP 2
b0 <- 0.2
b1 <- 0.5
n <- 1000 # sample size
X <- runif(n, -1, 1)
gamma <- 1.5
for (i in 1:reps){
Y <- b0 + b1 * X + rnorm(n, 0, exp(X * gamma)) # the heteroskedastic
model <- lm(Y ~ X)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
par.est[i, 5] <- sqrt(diag(vcovHC(model, type = "HC0"))[1]) # HC SE of b0.hat
par.est[i, 6] <- sqrt(diag(vcovHC(model, type = "HC0"))[2]) # HC SE of b1.hat
}
## (c)
## Plot the first 200 CIs in (b) and identify the CIs in color red that don’t cover true β1.
n <- c(0, 200)
Xbar <- c(-0.2,1.2)
plot(x = Xbar, y = n, type = "n")
abline(v = b1, lty = 2, col = "red")
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 1, col = "gray")
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 2, col = "red")
}
}
set.seed(123)
n <- 100 # sample size
# DGP 3
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n) # omitted variable
u <- rnorm(n) # error term
y <- 6 + 0.3 * x - 0.9 * w + u # true model
set.seed(123)
n <- 100   # sample size
# DGP 3
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
## (a)
## Plot the sampling distribution of b1.hat in the simple regression of
## Y on X with a vertical red line indicating the true value of β1
set.seed(123)
n <- 100   # sample size
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
View(par.est)
for (i in 1:reps){
# DGP 3
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(Y ~ X)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
set.seed(123)
n <- 100   # sample size
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
View(par.est)
## (a)
## Plot the sampling distribution of b1.hat in the simple regression of
## Y on X with a vertical red line indicating the true value of β1
set.seed(123)
n <- 100   # sample size
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
View(par.est)
View(par.est)
hist(par.est[, 2], nclass = 20, xlim = c(-0.5, 0.5), main = b1.hat)
hist(par.est[, 2], nclass = 20, xlim = c(-0.5, 0.5), main = "b1.hat")
hist(par.est[, 2], xlim = c(-0.5, 0.5), main = "b1.hat")
hist(par.est[, 2], nclass = 20, main = "b1.hat")
abline(v = b1, col = "red", lwd = 2)
abline(v = 0.3, col = "red", lwd = 2)
hist(par.est[, 2], nclass = 20, xlim = c(-0.5, 0.5), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
## (b)
## Compute the simulated bias of beta1 hat
bias.b1 <- mean(par.est[, 2]) - 0.3 # bias of b1.hat
bias.b1
set.seed(123)
n <- 100   # sample size
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
View(par.est)
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
hist(par.est[, 2], nclass = 20, xlim = c(-0.5, 0.4), main = "b1.hat")
6
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
bias.b1 <- mean(par.est[, 2]) - 0.3 # bias of b1.hat
bias.b1
library(sandwich)
set.seed(123)
reps <- 10000
par.est <- matrix(0, reps, 6)   # 10000 rows, 6 columns
# DGP 2
b0 <- 0.2
b1 <- 0.5
n <- 1000 # sample size
X <- runif(n, -1, 1)
gamma <- 1.5
for (i in 1:reps){
Y <- b0 + b1 * X + rnorm(n, 0, exp(X * gamma)) # the heteroskedastic
model <- lm(Y ~ X)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
par.est[i, 5] <- sqrt(diag(vcovHC(model, type = "HC0"))[1]) # HC SE of b0.hat
par.est[i, 6] <- sqrt(diag(vcovHC(model, type = "HC0"))[2]) # HC SE of b1.hat
}
n <- c(0, 200)
Xbar <- c(-0.2,1.2)
b1 <- 0.5
plot(x = Xbar, y = n, type = "n")
abline(v = b1, lty = 2, col = "red")
for (i in 1:200) {
ci_lower <- par.est[i, 2] - 1.96 * par.est[i, 6]
ci_upper <- par.est[i, 2] + 1.96 * par.est[i, 6]
if (b1 >= ci_lower && b1 <= ci_upper) {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 1, col = "gray")
} else {
lines(c(ci_lower,ci_upper), c(i,i), lty = 1, lwd = 2, col = "red")
}
}
set.seed(123)
n <- 100   # sample size
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
set.seed(123)
n <- 100   # sample size
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
View(par.est)
# bias of b1.hat
bias.b1 <- mean(par.est[, 2]) - 0.3   # -0.6143994
## (c)
## Compare the simulated bias in (b) with the theoretical bias from the OVB formula and discuss.
model <- lm(w ~ x)
View(model)
delta_hat <- model$coefficients[2]
theoretical_bias <- 0.3 + delta_hat * -0.9
theoretical_bias
delta_hat <- model$coefficients[[2]]
theoretical_bias <- 0.3 + delta_hat * -0.9
set.seed(123)
n <- 100   # sample size
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
## (b)
## Compute the simulated bias of beta1 hat
# bias of b1.hat
bias.b1 <- mean(par.est[, 2]) - 0.3   # -0.6143994
## (c)
model <- lm(w ~ x)
delta_hat <- model$coefficients[[2]]
bias.b1 <- 0.3 + delta_hat * -0.9
View(par.est)
## (a)
## Plot the sampling distribution of b1.hat in the simple regression of
## Y on X with a vertical red line indicating the true value of β1
set.seed(123)
n <- 100   # sample size
x <- rnorm(n, mean = 8, sd = 3)
w <- 0.7 * x + rnorm(n)   # omitted variable
reps <- 10000
par.est <- matrix(0, reps, 4)   # 10000 rows, 4 columns
for (i in 1:reps){
# DGP 3
u <- rnorm(n)   # error term
y <- 6 + 0.3 * x - 0.9 * w + u   # true model
model <- lm(y ~ x)
par.est[i, 1] <- model$coef[1] # b0.hat
par.est[i, 2] <- model$coef[2] # b1.hat
par.est[i, 3] <- sqrt(diag(vcov(model))[1]) # OLS SE of b0.hat
par.est[i, 4] <- sqrt(diag(vcov(model))[2]) # OLS SE of b1.hat
}
hist(par.est[, 2], nclass = 20, xlim = c(-0.6, 0.4), main = "b1.hat")
abline(v = 0.3, col = "red", lwd = 2)
## (b)
## Compute the simulated bias of beta1 hat
# bias of b1.hat
bias.b1 <- mean(par.est[, 2]) - 0.3   # -0.6143994
## (c)
## (c) Compare the simulated bias in (b) with the theoretical bias from the OVB formula and discuss.
model <- lm(w ~ x)
delta_hat <- model$coefficients[[2]]
theoretical.bias.b1 <- (0.3 + delta_hat * -0.9) - 0.3
setwd("~/Programming/R/NCCU_ds/HW/hw5-syeven143818-master/Titanic_Data")
